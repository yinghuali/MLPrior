{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtree</th>\n",
       "      <th>knn</th>\n",
       "      <th>lr</th>\n",
       "      <th>nb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>dtree</th>\n",
       "      <th>knn</th>\n",
       "      <th>lr</th>\n",
       "      <th>nb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>dtree</th>\n",
       "      <th>knn</th>\n",
       "      <th>lr</th>\n",
       "      <th>nb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_apfd</th>\n",
       "      <td>0.508</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepGini_apfd</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy_apfd</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcs_apfd</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanillasoftmax_apfd</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dtree    knn     lr     nb    xgb  dtree    knn     lr  \\\n",
       "random_apfd          0.508  0.506  0.493  0.505    0.5  0.502  0.494  0.504   \n",
       "deepGini_apfd        0.739  0.738  0.688   0.71  0.793   0.77  0.704  0.769   \n",
       "entropy_apfd         0.739  0.738  0.688   0.71  0.793   0.77  0.704  0.769   \n",
       "pcs_apfd             0.739  0.738  0.688   0.71  0.793   0.77  0.704  0.769   \n",
       "vanillasoftmax_apfd  0.739  0.738  0.688   0.71  0.793   0.77  0.704  0.769   \n",
       "dt                   0.706  0.715  0.786  0.787  0.742  0.747   0.79  0.801   \n",
       "knn                  0.787  0.775  0.737  0.739  0.729  0.823  0.775  0.784   \n",
       "lr                    0.74  0.743  0.722  0.672  0.688  0.786  0.769  0.757   \n",
       "nb                   0.787  0.775  0.737  0.739  0.729  0.823  0.775  0.784   \n",
       "xgb                   0.81  0.811  0.829   0.83  0.813  0.863  0.872  0.878   \n",
       "\n",
       "                        nb    xgb  dtree    knn     lr     nb    xgb  \n",
       "random_apfd           0.49  0.494  0.519  0.505  0.502  0.497  0.499  \n",
       "deepGini_apfd        0.694  0.837  0.768  0.604  0.593  0.615  0.758  \n",
       "entropy_apfd         0.694  0.837  0.768  0.604  0.593  0.615  0.758  \n",
       "pcs_apfd             0.694  0.837  0.768  0.604  0.593  0.615  0.758  \n",
       "vanillasoftmax_apfd  0.694  0.837  0.768  0.604  0.593  0.615  0.758  \n",
       "dt                   0.817  0.779  0.839  0.753  0.837  0.832  0.889  \n",
       "knn                  0.782  0.792  0.765  0.626  0.589  0.604  0.669  \n",
       "lr                   0.771  0.751  0.898  0.621  0.608  0.608  0.703  \n",
       "nb                   0.782  0.792  0.765  0.626  0.589  0.604  0.669  \n",
       "xgb                  0.877  0.868   0.99  0.787  0.845  0.839    0.9  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "def get_clean_path(path_dir_compile):\n",
    "    path_list = []\n",
    "    if os.path.isdir(path_dir_compile):\n",
    "        for root, dirs, files in os.walk(path_dir_compile, topdown=True):\n",
    "            for file in files:\n",
    "                file_absolute_path = os.path.join(root, file)\n",
    "                if file_absolute_path.endswith('.csv') and 'missing' not in file_absolute_path and 'noise' not in file_absolute_path:\n",
    "                    path_list.append(file_absolute_path)\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def read_all_csv(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        tmp_df = pd.read_csv(path)\n",
    "        data_name = path.split('/')[-1].split('_')[2]\n",
    "        model_name = path.split('/')[-1].split('_')[0]\n",
    "        tmp_df['data'] = data_name\n",
    "        tmp_df['model'] = model_name\n",
    "        df_list.append(tmp_df)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "data_list = ['adult', 'bank', 'stroke']\n",
    "approach_list = ['random_apfd','deepGini_apfd', 'entropy_apfd', 'pcs_apfd', 'vanillasoftmax_apfd', \n",
    "                'dt', 'knn', 'lr', 'nb', 'xgb']\n",
    "\n",
    "model_list = ['dtree', 'knn', 'lr', 'nb', 'xgb']\n",
    "\n",
    "path_list = get_clean_path('./result/')\n",
    "df = read_all_csv(path_list)\n",
    "\n",
    "all_list = []\n",
    "for approach in approach_list:\n",
    "    res_list = []\n",
    "    for data in data_list:\n",
    "        for model in model_list:\n",
    "            values = df[(df['Approach']==approach)&(df['data']==data)&(df['model']==model)]['apfd'].values[0]\n",
    "            values = str(round(values, 3))\n",
    "            res_list.append(values)\n",
    "    all_list.append(res_list)\n",
    "\n",
    "df = pd.DataFrame(all_list, columns=model_list*3, index=approach_list)\n",
    "df.to_excel('./tables/apfd_clean.xlsx', index=True)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average APFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtree</th>\n",
       "      <th>knn</th>\n",
       "      <th>lr</th>\n",
       "      <th>nb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>dtree</th>\n",
       "      <th>knn</th>\n",
       "      <th>lr</th>\n",
       "      <th>nb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>dtree</th>\n",
       "      <th>knn</th>\n",
       "      <th>lr</th>\n",
       "      <th>nb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_apfd</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepGini_apfd</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy_apfd</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcs_apfd</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanillasoftmax_apfd</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dtree    knn     lr     nb    xgb  dtree    knn     lr  \\\n",
       "random_apfd          0.499  0.499    0.5    0.5  0.501  0.498  0.502  0.497   \n",
       "deepGini_apfd         0.46  0.701  0.682  0.711  0.744   0.74  0.707  0.766   \n",
       "entropy_apfd          0.46  0.701  0.682  0.711  0.744   0.74  0.707  0.766   \n",
       "pcs_apfd              0.46  0.701  0.682  0.711  0.744   0.74  0.707  0.766   \n",
       "vanillasoftmax_apfd   0.46  0.701  0.682  0.711  0.744   0.74  0.707  0.766   \n",
       "dt                   0.771   0.74  0.776  0.781  0.773  0.812  0.791  0.801   \n",
       "knn                  0.741  0.746  0.718  0.727  0.736  0.813  0.783  0.778   \n",
       "lr                    0.68  0.714  0.678  0.677  0.688  0.813  0.745   0.76   \n",
       "nb                   0.741  0.746  0.718  0.727  0.736  0.813  0.783  0.778   \n",
       "xgb                   0.83   0.81  0.825  0.827  0.829  0.867  0.872  0.875   \n",
       "\n",
       "                        nb    xgb  dtree    knn     lr     nb    xgb  \n",
       "random_apfd          0.502    0.5  0.509    0.5  0.499  0.501  0.501  \n",
       "deepGini_apfd        0.676  0.826  0.702  0.602  0.593  0.611  0.755  \n",
       "entropy_apfd         0.676  0.826  0.702  0.602  0.593  0.611  0.755  \n",
       "pcs_apfd             0.676  0.826  0.702  0.602  0.593  0.611  0.755  \n",
       "vanillasoftmax_apfd  0.676  0.826  0.702  0.602  0.593  0.611  0.755  \n",
       "dt                   0.815   0.78  0.848  0.784  0.836  0.831  0.887  \n",
       "knn                  0.783   0.79  0.727  0.623  0.592  0.593  0.662  \n",
       "lr                   0.766  0.759   0.83  0.626  0.607  0.605   0.69  \n",
       "nb                   0.783   0.79  0.727  0.623  0.592  0.593  0.662  \n",
       "xgb                  0.875  0.868  0.982  0.825  0.845  0.838  0.898  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "def get_mixture_path(path_dir_compile):\n",
    "    path_list = []\n",
    "    if os.path.isdir(path_dir_compile):\n",
    "        for root, dirs, files in os.walk(path_dir_compile, topdown=True):\n",
    "            for file in files:\n",
    "                file_absolute_path = os.path.join(root, file)\n",
    "                if file_absolute_path.endswith('.csv') and 'mixture' in file_absolute_path:\n",
    "                    path_list.append(file_absolute_path)\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def read_all_csv(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        tmp_df = pd.read_csv(path)\n",
    "        model_name = path.split('/')[-1].split('_')[0]\n",
    "        data_type = path.split('/')[-1].split('_')[1]\n",
    "        data_name = path.split('/')[-1].split('_')[2]\n",
    "        tmp_df['data'] = data_name\n",
    "        tmp_df['data_type'] = data_type\n",
    "        tmp_df['model'] = model_name\n",
    "        df_list.append(tmp_df)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "data_list = ['adult', 'bank', 'stroke']\n",
    "approach_list = ['random_apfd','deepGini_apfd', 'entropy_apfd', 'pcs_apfd', 'vanillasoftmax_apfd', \n",
    "                'dt', 'knn', 'lr', 'nb', 'xgb']\n",
    "\n",
    "model_list = ['dtree', 'knn', 'lr', 'nb', 'xgb']\n",
    "\n",
    "path_list = get_mixture_path('./result/')\n",
    "\n",
    "df = read_all_csv(path_list)\n",
    "\n",
    "df_noise = df[df['data_type']=='noise']\n",
    "\n",
    "all_list = []\n",
    "for approach in approach_list:\n",
    "    res_list = []\n",
    "    for data in data_list:\n",
    "        for model in model_list:\n",
    "            tmp_df = df_noise[(df_noise['Approach']==approach)&(df_noise['data']==data)&(df_noise['model']==model)]\n",
    "            \n",
    "            values = tmp_df['apfd'].mean()\n",
    "            values = str(round(values, 3))\n",
    "\n",
    "            res_list.append(values)\n",
    "    all_list.append(res_list)\n",
    "        \n",
    "\n",
    "df_noise = pd.DataFrame(all_list, columns=model_list*3, index=approach_list)\n",
    "df_noise.to_excel('./tables/apfd_mixture_noise.xlsx', index=True)\n",
    "df_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577333333333332"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise.astype('float').to_numpy()[-1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_apfd': 0,\n",
       " 'deepGini_apfd': 0,\n",
       " 'vanillasoftmax_apfd': 0,\n",
       " 'pcs_apfd': 0,\n",
       " 'entropy_apfd': 0,\n",
       " 'xgb': 150}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = get_mixture_path('./result/')\n",
    "dic = {'random_apfd':0,\n",
    "       'deepGini_apfd':0,\n",
    "       'vanillasoftmax_apfd':0,\n",
    "       'pcs_apfd':0,\n",
    "       'entropy_apfd':0,\n",
    "       'xgb':0}\n",
    "\n",
    "path_list_compare = [i for i in path_list if 'compare' in i]\n",
    "path_list_model = [i.replace('compare', 'model') for i in path_list_compare]\n",
    "\n",
    "for i in range(len(path_list_compare)):\n",
    "    df_compare = pd.read_csv(path_list_compare[i])\n",
    "    df_model = pd.read_csv(path_list_model[i])\n",
    "    df_model = df[df['Approach']=='xgb']\n",
    "    df = pd.concat([df_compare, df_model], ignore_index=True)\n",
    "    tmp_dic = dict(zip(df['Approach'], df['apfd']))\n",
    "    max_key = max(tmp_dic,key=tmp_dic.get)\n",
    "    dic[max_key] += 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_apfd': 0,\n",
       " 'deepGini_apfd': 0,\n",
       " 'vanillasoftmax_apfd': 0,\n",
       " 'pcs_apfd': 0,\n",
       " 'entropy_apfd': 0,\n",
       " 'xgb': 150,\n",
       " 'dt': 0,\n",
       " 'knn': 0,\n",
       " 'lr': 0,\n",
       " 'nb': 0}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mixture data\n",
    "path_list = get_mixture_path('./result/')\n",
    "dic = {'random_apfd':0,\n",
    "       'deepGini_apfd':0,\n",
    "       'vanillasoftmax_apfd':0,\n",
    "       'pcs_apfd':0,\n",
    "       'entropy_apfd':0,\n",
    "       'xgb':0,\n",
    "       'dt': 0,\n",
    "       'knn':0,\n",
    "       'lr':0,\n",
    "       'nb':0\n",
    "      }\n",
    "\n",
    "path_list_compare = [i for i in path_list if 'compare' in i]\n",
    "path_list_model = [i.replace('compare', 'model') for i in path_list_compare]\n",
    "\n",
    "for i in range(len(path_list_compare)):\n",
    "    df_compare = pd.read_csv(path_list_compare[i])\n",
    "    df_model = pd.read_csv(path_list_model[i])\n",
    "    df = pd.concat([df_compare, df_model], ignore_index=True)\n",
    "    tmp_dic = dict(zip(df['Approach'], df['apfd']))\n",
    "    max_key = max(tmp_dic,key=tmp_dic.get)\n",
    "    dic[max_key] += 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_apfd': 0,\n",
       " 'deepGini_apfd': 0,\n",
       " 'vanillasoftmax_apfd': 0,\n",
       " 'pcs_apfd': 0,\n",
       " 'entropy_apfd': 0,\n",
       " 'xgb': 15,\n",
       " 'dt': 0,\n",
       " 'knn': 0,\n",
       " 'lr': 0,\n",
       " 'nb': 0}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data\n",
    "path_list = get_clean_path('./result/')\n",
    "dic = {'random_apfd':0,\n",
    "       'deepGini_apfd':0,\n",
    "       'vanillasoftmax_apfd':0,\n",
    "       'pcs_apfd':0,\n",
    "       'entropy_apfd':0,\n",
    "       'xgb':0,\n",
    "       'dt': 0,\n",
    "       'knn':0,\n",
    "       'lr':0,\n",
    "       'nb':0\n",
    "      }\n",
    "\n",
    "path_list_compare = [i for i in path_list if 'compare' in i]\n",
    "path_list_model = [i.replace('compare', 'model') for i in path_list_compare]\n",
    "\n",
    "for i in range(len(path_list_compare)):\n",
    "    df_compare = pd.read_csv(path_list_compare[i])\n",
    "    df_model = pd.read_csv(path_list_model[i])\n",
    "    df = pd.concat([df_compare, df_model], ignore_index=True)\n",
    "    tmp_dic = dict(zip(df['Approach'], df['apfd']))\n",
    "    max_key = max(tmp_dic,key=tmp_dic.get)\n",
    "    dic[max_key] += 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_apfd': 0,\n",
       " 'deepGini_apfd': 0,\n",
       " 'vanillasoftmax_apfd': 0,\n",
       " 'pcs_apfd': 0,\n",
       " 'entropy_apfd': 0,\n",
       " 'xgb': 150,\n",
       " 'dt': 0,\n",
       " 'knn': 0,\n",
       " 'lr': 0,\n",
       " 'nb': 0}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data\n",
    "path_list = get_mixture_path('./result/')\n",
    "dic = {'random_apfd':0,\n",
    "       'deepGini_apfd':0,\n",
    "       'vanillasoftmax_apfd':0,\n",
    "       'pcs_apfd':0,\n",
    "       'entropy_apfd':0,\n",
    "       'xgb':0,\n",
    "       'dt': 0,\n",
    "       'knn':0,\n",
    "       'lr':0,\n",
    "       'nb':0\n",
    "      }\n",
    "\n",
    "path_list_compare = [i for i in path_list if 'compare' in i]\n",
    "path_list_model = [i.replace('compare', 'model') for i in path_list_compare]\n",
    "\n",
    "for i in range(len(path_list_compare)):\n",
    "    df_compare = pd.read_csv(path_list_compare[i])\n",
    "    df_model = pd.read_csv(path_list_model[i])\n",
    "    df = pd.concat([df_compare, df_model], ignore_index=True)\n",
    "    tmp_dic = dict(zip(df['Approach'], df['apfd']))\n",
    "    max_key = max(tmp_dic,key=tmp_dic.get)\n",
    "    dic[max_key] += 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7948666666666667\n",
      "0.7262666666666667\n",
      "0.7158333333333335\n",
      "0.7262666666666667\n"
     ]
    }
   ],
   "source": [
    "MLPriorùëá=[0.706,0.715,0.786,0.787,0.742,0.747,0.790,0.801,0.817,0.779,0.839,0.753,0.837,0.832,0.889,0.771,0.740,0.776,0.781,0.773,0.812,0.791,0.801,0.815,0.780,0.848,0.784,0.836,0.831,0.887]\n",
    "MLPriorùêæ=[0.787,0.775,0.737,0.739,0.729,0.823,0.775,0.784,0.782,0.792,0.765,0.626,0.589,0.604,0.669,0.741,0.746,0.718,0.727,0.736,0.813,0.783,0.778,0.783,0.790,0.727,0.623,0.592,0.593,0.662]\n",
    "MLPriorùêø=[0.740,0.743,0.722,0.672,0.688,0.786,0.769,0.757,0.771,0.751,0.898,0.621,0.608,0.608,0.703,0.680,0.714,0.678,0.677,0.688,0.813,0.745,0.760,0.766,0.759,0.830,0.626,0.607,0.605,0.690]\n",
    "MLPriorùëÅ=[0.787,0.775,0.737,0.739,0.729,0.823,0.775,0.784,0.782,0.792,0.765,0.626,0.589,0.604,0.669,0.741,0.746,0.718,0.727,0.736,0.813,0.783,0.778,0.783,0.790,0.727,0.623,0.592,0.593,0.662]\n",
    "\n",
    "print(sum(MLPriorùëá)/len(MLPriorùëá))\n",
    "print(sum(MLPriorK)/len(MLPriorK))\n",
    "print(sum(MLPriorL)/len(MLPriorL))\n",
    "print(sum(MLPriorN)/len(MLPriorN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_feature</th>\n",
       "      <th>0_value</th>\n",
       "      <th>1_feature</th>\n",
       "      <th>1_value</th>\n",
       "      <th>2_feature</th>\n",
       "      <th>2_value</th>\n",
       "      <th>3_feature</th>\n",
       "      <th>3_value</th>\n",
       "      <th>4_feature</th>\n",
       "      <th>4_value</th>\n",
       "      <th>5_feature</th>\n",
       "      <th>5_value</th>\n",
       "      <th>6_feature</th>\n",
       "      <th>6_value</th>\n",
       "      <th>7_feature</th>\n",
       "      <th>7_value</th>\n",
       "      <th>8_feature</th>\n",
       "      <th>8_value</th>\n",
       "      <th>9_feature</th>\n",
       "      <th>9_value</th>\n",
       "      <th>10_feature</th>\n",
       "      <th>10_value</th>\n",
       "      <th>11_feature</th>\n",
       "      <th>11_value</th>\n",
       "      <th>12_feature</th>\n",
       "      <th>12_value</th>\n",
       "      <th>13_feature</th>\n",
       "      <th>13_value</th>\n",
       "      <th>14_feature</th>\n",
       "      <th>14_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f21</td>\n",
       "      <td>1544</td>\n",
       "      <td>f44</td>\n",
       "      <td>2786</td>\n",
       "      <td>f127</td>\n",
       "      <td>3140</td>\n",
       "      <td>f123</td>\n",
       "      <td>1653</td>\n",
       "      <td>f118</td>\n",
       "      <td>2976</td>\n",
       "      <td>f25</td>\n",
       "      <td>1410</td>\n",
       "      <td>f49</td>\n",
       "      <td>1851</td>\n",
       "      <td>f131</td>\n",
       "      <td>1447</td>\n",
       "      <td>f122</td>\n",
       "      <td>2313</td>\n",
       "      <td>f126</td>\n",
       "      <td>1566</td>\n",
       "      <td>f4</td>\n",
       "      <td>1006</td>\n",
       "      <td>f28</td>\n",
       "      <td>1534</td>\n",
       "      <td>f124</td>\n",
       "      <td>844</td>\n",
       "      <td>f110</td>\n",
       "      <td>1526</td>\n",
       "      <td>f4</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f10</td>\n",
       "      <td>1358</td>\n",
       "      <td>f45</td>\n",
       "      <td>2658</td>\n",
       "      <td>f129</td>\n",
       "      <td>2550</td>\n",
       "      <td>f29</td>\n",
       "      <td>1605</td>\n",
       "      <td>f120</td>\n",
       "      <td>2674</td>\n",
       "      <td>f4</td>\n",
       "      <td>1053</td>\n",
       "      <td>f17</td>\n",
       "      <td>1427</td>\n",
       "      <td>f117</td>\n",
       "      <td>1417</td>\n",
       "      <td>f31</td>\n",
       "      <td>1499</td>\n",
       "      <td>f8</td>\n",
       "      <td>1061</td>\n",
       "      <td>f5</td>\n",
       "      <td>758</td>\n",
       "      <td>f18</td>\n",
       "      <td>1080</td>\n",
       "      <td>f115</td>\n",
       "      <td>783</td>\n",
       "      <td>f83</td>\n",
       "      <td>736</td>\n",
       "      <td>f111</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f11</td>\n",
       "      <td>1342</td>\n",
       "      <td>f19</td>\n",
       "      <td>2127</td>\n",
       "      <td>f131</td>\n",
       "      <td>1970</td>\n",
       "      <td>f127</td>\n",
       "      <td>1369</td>\n",
       "      <td>f5</td>\n",
       "      <td>1660</td>\n",
       "      <td>f22</td>\n",
       "      <td>1040</td>\n",
       "      <td>f35</td>\n",
       "      <td>1262</td>\n",
       "      <td>f120</td>\n",
       "      <td>1199</td>\n",
       "      <td>f72</td>\n",
       "      <td>1380</td>\n",
       "      <td>f123</td>\n",
       "      <td>1042</td>\n",
       "      <td>f7</td>\n",
       "      <td>706</td>\n",
       "      <td>f38</td>\n",
       "      <td>985</td>\n",
       "      <td>f7</td>\n",
       "      <td>718</td>\n",
       "      <td>f2</td>\n",
       "      <td>465</td>\n",
       "      <td>f122</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f5</td>\n",
       "      <td>1096</td>\n",
       "      <td>f26</td>\n",
       "      <td>1536</td>\n",
       "      <td>f5</td>\n",
       "      <td>1175</td>\n",
       "      <td>f5</td>\n",
       "      <td>1362</td>\n",
       "      <td>f131</td>\n",
       "      <td>1586</td>\n",
       "      <td>f7</td>\n",
       "      <td>710</td>\n",
       "      <td>f46</td>\n",
       "      <td>1096</td>\n",
       "      <td>f4</td>\n",
       "      <td>1148</td>\n",
       "      <td>f27</td>\n",
       "      <td>1096</td>\n",
       "      <td>f4</td>\n",
       "      <td>964</td>\n",
       "      <td>f8</td>\n",
       "      <td>625</td>\n",
       "      <td>f29</td>\n",
       "      <td>952</td>\n",
       "      <td>f4</td>\n",
       "      <td>648</td>\n",
       "      <td>f35</td>\n",
       "      <td>430</td>\n",
       "      <td>f2</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2</td>\n",
       "      <td>630</td>\n",
       "      <td>f49</td>\n",
       "      <td>1429</td>\n",
       "      <td>f126</td>\n",
       "      <td>1093</td>\n",
       "      <td>f10</td>\n",
       "      <td>1339</td>\n",
       "      <td>f126</td>\n",
       "      <td>1460</td>\n",
       "      <td>f8</td>\n",
       "      <td>696</td>\n",
       "      <td>f8</td>\n",
       "      <td>971</td>\n",
       "      <td>f7</td>\n",
       "      <td>1094</td>\n",
       "      <td>f127</td>\n",
       "      <td>1080</td>\n",
       "      <td>f134</td>\n",
       "      <td>953</td>\n",
       "      <td>f1</td>\n",
       "      <td>530</td>\n",
       "      <td>f4</td>\n",
       "      <td>827</td>\n",
       "      <td>f8</td>\n",
       "      <td>645</td>\n",
       "      <td>f55</td>\n",
       "      <td>424</td>\n",
       "      <td>f3</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f9</td>\n",
       "      <td>585</td>\n",
       "      <td>f5</td>\n",
       "      <td>1252</td>\n",
       "      <td>f10</td>\n",
       "      <td>961</td>\n",
       "      <td>f67</td>\n",
       "      <td>1217</td>\n",
       "      <td>f10</td>\n",
       "      <td>1429</td>\n",
       "      <td>f18</td>\n",
       "      <td>527</td>\n",
       "      <td>f31</td>\n",
       "      <td>933</td>\n",
       "      <td>f135</td>\n",
       "      <td>794</td>\n",
       "      <td>f58</td>\n",
       "      <td>1001</td>\n",
       "      <td>f129</td>\n",
       "      <td>874</td>\n",
       "      <td>f16</td>\n",
       "      <td>507</td>\n",
       "      <td>f42</td>\n",
       "      <td>801</td>\n",
       "      <td>f113</td>\n",
       "      <td>541</td>\n",
       "      <td>f28</td>\n",
       "      <td>320</td>\n",
       "      <td>f8</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f23</td>\n",
       "      <td>576</td>\n",
       "      <td>f31</td>\n",
       "      <td>1124</td>\n",
       "      <td>f11</td>\n",
       "      <td>793</td>\n",
       "      <td>f82</td>\n",
       "      <td>1172</td>\n",
       "      <td>f11</td>\n",
       "      <td>1140</td>\n",
       "      <td>f13</td>\n",
       "      <td>508</td>\n",
       "      <td>f27</td>\n",
       "      <td>929</td>\n",
       "      <td>f122</td>\n",
       "      <td>730</td>\n",
       "      <td>f60</td>\n",
       "      <td>989</td>\n",
       "      <td>f7</td>\n",
       "      <td>753</td>\n",
       "      <td>f18</td>\n",
       "      <td>415</td>\n",
       "      <td>f7</td>\n",
       "      <td>728</td>\n",
       "      <td>f127</td>\n",
       "      <td>530</td>\n",
       "      <td>f5</td>\n",
       "      <td>251</td>\n",
       "      <td>f7</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f17</td>\n",
       "      <td>544</td>\n",
       "      <td>f53</td>\n",
       "      <td>1122</td>\n",
       "      <td>f114</td>\n",
       "      <td>773</td>\n",
       "      <td>f11</td>\n",
       "      <td>1016</td>\n",
       "      <td>f128</td>\n",
       "      <td>809</td>\n",
       "      <td>f11</td>\n",
       "      <td>495</td>\n",
       "      <td>f42</td>\n",
       "      <td>923</td>\n",
       "      <td>f8</td>\n",
       "      <td>721</td>\n",
       "      <td>f4</td>\n",
       "      <td>798</td>\n",
       "      <td>f128</td>\n",
       "      <td>718</td>\n",
       "      <td>f12</td>\n",
       "      <td>401</td>\n",
       "      <td>f40</td>\n",
       "      <td>696</td>\n",
       "      <td>f5</td>\n",
       "      <td>472</td>\n",
       "      <td>f112</td>\n",
       "      <td>241</td>\n",
       "      <td>f123</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f13</td>\n",
       "      <td>538</td>\n",
       "      <td>f10</td>\n",
       "      <td>1083</td>\n",
       "      <td>f117</td>\n",
       "      <td>759</td>\n",
       "      <td>f43</td>\n",
       "      <td>1005</td>\n",
       "      <td>f13</td>\n",
       "      <td>778</td>\n",
       "      <td>f5</td>\n",
       "      <td>369</td>\n",
       "      <td>f41</td>\n",
       "      <td>828</td>\n",
       "      <td>f11</td>\n",
       "      <td>584</td>\n",
       "      <td>f86</td>\n",
       "      <td>785</td>\n",
       "      <td>f122</td>\n",
       "      <td>610</td>\n",
       "      <td>f9</td>\n",
       "      <td>394</td>\n",
       "      <td>f5</td>\n",
       "      <td>589</td>\n",
       "      <td>f122</td>\n",
       "      <td>426</td>\n",
       "      <td>f45</td>\n",
       "      <td>165</td>\n",
       "      <td>f5</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f15</td>\n",
       "      <td>498</td>\n",
       "      <td>f16</td>\n",
       "      <td>1061</td>\n",
       "      <td>f115</td>\n",
       "      <td>692</td>\n",
       "      <td>f129</td>\n",
       "      <td>976</td>\n",
       "      <td>f2</td>\n",
       "      <td>594</td>\n",
       "      <td>f6</td>\n",
       "      <td>363</td>\n",
       "      <td>f55</td>\n",
       "      <td>807</td>\n",
       "      <td>f13</td>\n",
       "      <td>556</td>\n",
       "      <td>f108</td>\n",
       "      <td>784</td>\n",
       "      <td>f6</td>\n",
       "      <td>521</td>\n",
       "      <td>f3</td>\n",
       "      <td>390</td>\n",
       "      <td>f8</td>\n",
       "      <td>579</td>\n",
       "      <td>f114</td>\n",
       "      <td>352</td>\n",
       "      <td>f8</td>\n",
       "      <td>129</td>\n",
       "      <td>f1</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0_feature  0_value 1_feature  1_value 2_feature  2_value 3_feature  3_value  \\\n",
       "0       f21     1544       f44     2786      f127     3140      f123     1653   \n",
       "1       f10     1358       f45     2658      f129     2550       f29     1605   \n",
       "2       f11     1342       f19     2127      f131     1970      f127     1369   \n",
       "3        f5     1096       f26     1536        f5     1175        f5     1362   \n",
       "4        f2      630       f49     1429      f126     1093       f10     1339   \n",
       "5        f9      585        f5     1252       f10      961       f67     1217   \n",
       "6       f23      576       f31     1124       f11      793       f82     1172   \n",
       "7       f17      544       f53     1122      f114      773       f11     1016   \n",
       "8       f13      538       f10     1083      f117      759       f43     1005   \n",
       "9       f15      498       f16     1061      f115      692      f129      976   \n",
       "\n",
       "  4_feature  4_value 5_feature  5_value 6_feature  6_value 7_feature  7_value  \\\n",
       "0      f118     2976       f25     1410       f49     1851      f131     1447   \n",
       "1      f120     2674        f4     1053       f17     1427      f117     1417   \n",
       "2        f5     1660       f22     1040       f35     1262      f120     1199   \n",
       "3      f131     1586        f7      710       f46     1096        f4     1148   \n",
       "4      f126     1460        f8      696        f8      971        f7     1094   \n",
       "5       f10     1429       f18      527       f31      933      f135      794   \n",
       "6       f11     1140       f13      508       f27      929      f122      730   \n",
       "7      f128      809       f11      495       f42      923        f8      721   \n",
       "8       f13      778        f5      369       f41      828       f11      584   \n",
       "9        f2      594        f6      363       f55      807       f13      556   \n",
       "\n",
       "  8_feature  8_value 9_feature  9_value 10_feature  10_value 11_feature  \\\n",
       "0      f122     2313      f126     1566         f4      1006        f28   \n",
       "1       f31     1499        f8     1061         f5       758        f18   \n",
       "2       f72     1380      f123     1042         f7       706        f38   \n",
       "3       f27     1096        f4      964         f8       625        f29   \n",
       "4      f127     1080      f134      953         f1       530         f4   \n",
       "5       f58     1001      f129      874        f16       507        f42   \n",
       "6       f60      989        f7      753        f18       415         f7   \n",
       "7        f4      798      f128      718        f12       401        f40   \n",
       "8       f86      785      f122      610         f9       394         f5   \n",
       "9      f108      784        f6      521         f3       390         f8   \n",
       "\n",
       "   11_value 12_feature  12_value 13_feature  13_value 14_feature  14_value  \n",
       "0      1534       f124       844       f110      1526         f4      1523  \n",
       "1      1080       f115       783        f83       736       f111      1322  \n",
       "2       985         f7       718         f2       465       f122       807  \n",
       "3       952         f4       648        f35       430         f2       729  \n",
       "4       827         f8       645        f55       424         f3       706  \n",
       "5       801       f113       541        f28       320         f8       482  \n",
       "6       728       f127       530         f5       251         f7       455  \n",
       "7       696         f5       472       f112       241       f123       393  \n",
       "8       589       f122       426        f45       165         f5       363  \n",
       "9       579       f114       352         f8       129         f1       267  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_path(path_dir_compile):\n",
    "    path_list = []\n",
    "    if os.path.isdir(path_dir_compile):\n",
    "        for root, dirs, files in os.walk(path_dir_compile, topdown=True):\n",
    "            for file in files:\n",
    "                file_absolute_path = os.path.join(root, file)\n",
    "                if file_absolute_path.endswith('.json'):\n",
    "                    path_list.append(file_absolute_path)\n",
    "    return path_list\n",
    "\n",
    "path_json_list = sorted(get_path('importance/'))\n",
    "data_list = [i.split('/')[-1].split('_')[1] for i in path_json_list]\n",
    "model_list = [i.split('/')[-1].split('_')[-1].split('.')[0] for i in path_json_list]\n",
    "\n",
    "dic_list = [json.load(open(i, 'r')) for i in path_json_list]\n",
    "\n",
    "df_all = pd.DataFrame(columns=['0'+'_'+'feature'])\n",
    "for i in range(len(dic_list)):\n",
    "    df = pd.DataFrame([dic_list[i]]).T.reset_index().rename(columns={\"index\": \"feature\", 0: \"value\"}).sort_values(by=['value'], ascending=False).head(10)\n",
    "    \n",
    "    df_all[str(i)+'_'+'feature'] = df['feature']\n",
    "    df_all[str(i)+'_'+'value'] = df['value'].astype(int)\n",
    "df_all.to_excel('./tables/feature_importance.xlsx', index=True)  \n",
    "df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'bank',\n",
       " 'bank',\n",
       " 'bank',\n",
       " 'bank',\n",
       " 'bank',\n",
       " 'stroke',\n",
       " 'stroke',\n",
       " 'stroke',\n",
       " 'stroke',\n",
       " 'stroke']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn',\n",
       " 'lr',\n",
       " 'nb',\n",
       " 'tree',\n",
       " 'xgb',\n",
       " 'knn',\n",
       " 'lr',\n",
       " 'nb',\n",
       " 'tree',\n",
       " 'xgb',\n",
       " 'knn',\n",
       " 'lr',\n",
       " 'nb',\n",
       " 'tree',\n",
       " 'xgb']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
